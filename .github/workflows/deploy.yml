name: Aluminum Price Crawler
on:
  schedule:
    - cron: '5 2 * * *'  # 每天UTC 0:10（北京时间8:10）
  workflow_dispatch:  # 允许手动触发

jobs:
  crawl-and-update:
    runs-on: ubuntu-latest
    steps:
    
      # 1. 检出代码（使用PAT确保写入权限）
      - name: Checkout Repository
        uses: actions/checkout@v3
        with:
          token: ${{ secrets.GH_PAGES_TOKEN }}
          ref: main

      # 2. 设置Python环境
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'

      # 3. 安装依赖
      - name: Install Dependencies
        run: |
          python -m pip install --upgrade pip
          pip install requests beautifulsoup4 lxml

      # 4. 运行爬虫脚本
      - name: Run Crawler
        run: python aluminum_price_crawler.py

      # 5. 文件验证（调试关键）
      - name: Verify JSON File
        run: |
          echo "当前目录: $(pwd)"
          ls -la
          echo "文件内容:"
          cat aluminum_prices.json | jq .  # 需要安装jq

      # 6. 提交更新（自动检测变更）
      - name: Commit & Push
        run: |
          git config --global user.name "GitHub Actions"
          git config --global user.email "actions@github.com"
          git add aluminum_prices.json
          # 仅当有变更时提交
          if git diff-index --quiet HEAD --; then
            echo "无数据变更，跳过提交"
          else
            git commit -m "Auto-update: Aluminum price $(date +'%Y-%m-%d %H:%M')"
            git push origin main
            echo "数据已提交"
          fi
        env:
          GITHUB_TOKEN: ${{ secrets.GH_PAGES_TOKEN }}

      # 7. 清理缓存（防止旧数据干扰）
      - name: Clean Cache
        run: |
          sudo rm -rf /usr/local/lib/python*
          sudo rm -rf ~/.cache/pip

      # 8. 部署到GitHub Pages（放在最后）
      - name: Deploy to GitHub Pages
        uses: peaceiris/actions-gh-pages@v3
        with:
          # 关键修改：使用自定义Token替代默认GITHUB_TOKEN
          github_token: ${{ secrets.GH_PAGES_TOKEN }}  # 指向新创建的Secret
          publish_dir: ./    # 发布根目录下的文件
          publish_branch: gh-pages  # 目标分支
